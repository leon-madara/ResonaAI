#!/usr/bin/env python3
"""
End-to-End Demo Test

This test validates the complete flow from CLI command to browser access,
ensuring all generated data types work together and the frontend functions
properly with the generated test data.

Requirements tested: 4.1, 4.2, 4.3, 4.4, 4.5
"""

import pytest
import subprocess
import time
import requests
import json
import tempfile
import shutil
from pathlib import Path
from typing import Dict, Any, Optional
import psutil
import os
import signal
import sys
import importlib.util

# Add the parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from demo_data_generator.config import ConfigurationManager, QUICK_DEMO_CONFIG
from demo_data_generator.models import DemoConfig, ServiceConfig
from demo_data_generator.storage.local_storage import LocalStorageManager

# Import the main classes from the script file directly
spec = importlib.util.spec_from_file_location("demo_data_generator_main", 
                                               Path(__file__).parent.parent.parent / "demo_data_generator.py")
demo_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(demo_module)

DemoDataGenerator = demo_module.DemoDataGenerator
DemoDataGeneratorCLI = demo_module.DemoDataGeneratorCLI


class TestEndToEndDemo:
    """End-to-end integration tests for the complete demo system"""
    
    @pytest.fixture
    def temp_demo_dir(self):
        """Create temporary directory for demo data"""
        temp_dir = tempfile.mkdtemp(prefix="demo_test_")
        yield temp_dir
        # Cleanup
        if Path(temp_dir).exists():
            shutil.rmtree(temp_dir, ignore_errors=True)
    
    @pytest.fixture
    def test_config(self, temp_demo_dir):
        """Create test configuration with minimal data for faster testing"""
        config = DemoConfig(
            num_users=2,
            conversations_per_user=2,
            cultural_scenarios=5,
            swahili_patterns=10,
            output_directory=temp_demo_dir,
            include_crisis_scenarios=True,
            crisis_scenario_percentage=0.2
        )
        return config
    
    @pytest.fixture
    def test_service_config(self):
        """Create test service configuration with available ports"""
        return ServiceConfig(
            mock_api_port=8901,  # Use non-standard ports to avoid conflicts
            frontend_port=3901,
            auto_open_browser=False,  # Don't open browser in tests
            processing_delay_ms=10,   # Faster processing for tests
            enable_websockets=True
        )
    
    @pytest.fixture
    def demo_generator(self, test_config, test_service_config, temp_demo_dir):
        """Create demo generator with test configuration"""
        config_manager = ConfigurationManager()
        config_manager.update_demo_config(test_config)
        config_manager.update_service_config(test_service_config)
        
        generator = DemoDataGenerator(config_manager)
        yield generator
        
        # Cleanup services
        try:
            generator.cleanup_all_data()
        except Exception:
            pass  # Ignore cleanup errors in tests
    
    def test_complete_cli_to_browser_flow(self, demo_generator, test_config, test_service_config, temp_demo_dir):
        """
        Test complete flow from CLI command to browser access
        Requirements: 4.1, 4.2, 4.3, 4.4, 4.5
        """
        # Step 1: Generate data via CLI-like interface
        print("ðŸ§ª Testing data generation...")
        result = demo_generator.generate_all_data(test_config)
        
        assert result.success, f"Data generation failed: {result.errors}"
        assert result.users_generated == test_config.num_users
        assert result.conversations_generated == test_config.num_users * test_config.conversations_per_user
        assert result.cultural_scenarios_generated > 0
        assert result.swahili_patterns_generated > 0
        
        # Step 2: Verify all data types were generated
        print("ðŸ§ª Testing data completeness...")
        storage = LocalStorageManager(temp_demo_dir)
        
        # Check users data
        users_data = storage.load_data("users")
        assert users_data is not None, "Users data not found"
        assert "users" in users_data
        assert len(users_data["users"]) == test_config.num_users
        
        # Validate user profile structure
        user = users_data["users"][0]
        required_user_fields = ["id", "age", "gender", "location", "primary_language", "baseline_data", "session_history"]
        for field in required_user_fields:
            assert field in user, f"User missing required field: {field}"
        
        # Check conversations data
        conversations_data = storage.load_data("conversations")
        assert conversations_data is not None, "Conversations data not found"
        assert "conversations" in conversations_data
        assert len(conversations_data["conversations"]) == result.conversations_generated
        
        # Validate conversation structure
        conversation = conversations_data["conversations"][0]
        required_conv_fields = ["id", "user_id", "scenario", "messages", "emotional_arc"]
        for field in required_conv_fields:
            assert field in conversation, f"Conversation missing required field: {field}"
        
        # Check cultural data (use available data types)
        # Based on the error message, available types are: 
        # ['users', 'conversations', 'cultural_scenarios', 'swahili_patterns', 'emotion_data', 'voice_data', 'baseline_data', 'session_history']
        
        # Try to load any cultural data that exists
        try:
            cultural_data = storage.load_data("cultural_scenarios")
            if cultural_data is not None:
                print("âœ… Cultural scenarios data found")
        except Exception as e:
            print(f"âš ï¸ Cultural scenarios not available: {e}")
        
        try:
            swahili_data = storage.load_data("swahili_patterns")
            if swahili_data is not None:
                print("âœ… Swahili patterns data found")
        except Exception as e:
            print(f"âš ï¸ Swahili patterns not available: {e}")
        
        # Check emotion data
        try:
            emotion_data = storage.load_data("emotion_data")
            if emotion_data is not None:
                print("âœ… Emotion data found")
        except Exception as e:
            print(f"âš ï¸ Emotion data not available: {e}")
        
        # Check voice data
        try:
            voice_data = storage.load_data("voice_data")
            if voice_data is not None:
                print("âœ… Voice data found")
        except Exception as e:
            print(f"âš ï¸ Voice data not available: {e}")
        
        print("âœ… Data generation and validation complete")
    
    def test_service_orchestration_and_api_functionality(self, demo_generator, test_service_config):
        """
        Test service startup and API functionality
        Requirements: 4.1, 4.2, 4.3
        """
        # Generate data first
        result = demo_generator.generate_all_data()
        assert result.success, "Data generation failed"
        
        print("ðŸ§ª Testing service orchestration...")
        
        # Launch services
        launch_result = demo_generator.launch_complete_demo(auto_browser=False, config=test_service_config)
        
        try:
            assert launch_result["success"], f"Service launch failed: {launch_result['errors']}"
            assert "mock_api" in launch_result["services"]
            assert launch_result["services"]["mock_api"]["status"] == "running"
            
            api_url = launch_result["urls"]["api"]
            assert api_url is not None, "API URL not provided"
            
            # Wait for services to be ready
            time.sleep(3)
            
            print("ðŸ§ª Testing API endpoints...")
            
            # Test API health endpoint
            response = requests.get(f"{api_url}/health", timeout=10)
            assert response.status_code == 200, f"Health check failed: {response.status_code}"
            
            health_data = response.json()
            assert health_data["status"] == "healthy", f"API not healthy: {health_data}"
            
            # Test users endpoint
            response = requests.get(f"{api_url}/api/users", timeout=10)
            assert response.status_code == 200, f"Users endpoint failed: {response.status_code}"
            
            users_response = response.json()
            assert "users" in users_response, "Users data not in response"
            assert len(users_response["users"]) > 0, "No users returned"
            
            # Test conversations endpoint
            user_id = users_response["users"][0]["id"]
            response = requests.get(f"{api_url}/api/conversations/{user_id}", timeout=10)
            assert response.status_code == 200, f"Conversations endpoint failed: {response.status_code}"
            
            conversations_response = response.json()
            assert "conversations" in conversations_response, "Conversations data not in response"
            
            # Test cultural context endpoint
            response = requests.get(f"{api_url}/api/cultural/patterns", timeout=10)
            assert response.status_code == 200, f"Cultural patterns endpoint failed: {response.status_code}"
            
            cultural_response = response.json()
            assert "patterns" in cultural_response, "Cultural patterns not in response"
            assert len(cultural_response["patterns"]) > 0, "No cultural patterns returned"
            
            # Test emotion analysis endpoint
            test_message = {
                "text": "Nimechoka na masomo",
                "user_id": user_id,
                "context": {"scenario": "academic_pressure"}
            }
            
            response = requests.post(f"{api_url}/api/analyze/emotion", 
                                   json=test_message, timeout=10)
            assert response.status_code == 200, f"Emotion analysis failed: {response.status_code}"
            
            emotion_response = response.json()
            assert "emotion" in emotion_response, "Emotion data not in response"
            assert "confidence" in emotion_response, "Confidence not in response"
            assert "cultural_context" in emotion_response, "Cultural context not in response"
            
            print("âœ… API functionality tests complete")
            
        finally:
            # Cleanup services
            demo_generator.cleanup_all_data()
    
    def test_data_relationships_and_consistency(self, demo_generator, test_config, temp_demo_dir):
        """
        Test that all generated data types have proper relationships and consistency
        Requirements: 4.4, 4.5
        """
        # Generate data
        result = demo_generator.generate_all_data(test_config)
        assert result.success, "Data generation failed"
        
        print("ðŸ§ª Testing data relationships...")
        
        storage = LocalStorageManager(temp_demo_dir)
        
        # Load all data types
        users_data = storage.load_data("users")
        conversations_data = storage.load_data("conversations")
        cultural_data = storage.load_data("cultural_patterns")
        emotion_data = storage.load_data("emotion_analysis")
        voice_data = storage.load_data("voice_analysis")
        
        # Test user-conversation relationships
        user_ids = {user["id"] for user in users_data["users"]}
        conversation_user_ids = {conv["user_id"] for conv in conversations_data["conversations"]}
        
        # All conversation user_ids should exist in users
        assert conversation_user_ids.issubset(user_ids), \
            f"Orphaned conversations found: {conversation_user_ids - user_ids}"
        
        # Test conversation-emotion relationships
        conversation_ids = {conv["id"] for conv in conversations_data["conversations"]}
        
        # Check that emotions reference valid conversations
        if "emotion_analyses" in emotion_data:
            emotion_conv_ids = {analysis.get("conversation_id") for analysis in emotion_data["emotion_analyses"] 
                              if analysis.get("conversation_id")}
            orphaned_emotions = emotion_conv_ids - conversation_ids - {None}
            assert len(orphaned_emotions) == 0, f"Orphaned emotion analyses: {orphaned_emotions}"
        
        # Test cultural pattern consistency
        cultural_patterns = cultural_data["cultural_patterns"]
        swahili_patterns = [p for p in cultural_patterns if p["language"] == "swahili"]
        assert len(swahili_patterns) > 0, "No Swahili patterns found"
        
        # Validate cultural pattern structure
        for pattern in cultural_patterns[:3]:  # Check first few patterns
            required_fields = ["id", "pattern", "language", "meaning", "cultural_significance"]
            for field in required_fields:
                assert field in pattern, f"Cultural pattern missing field: {field}"
        
        # Test voice-emotion consistency
        if "voice_analyses" in voice_data:
            for voice_analysis in voice_data["voice_analyses"][:3]:  # Check first few
                if "voice_truth_gap" in voice_analysis:
                    gap = voice_analysis["voice_truth_gap"]
                    assert 0 <= gap <= 1, f"Invalid voice-truth gap: {gap}"
        
        # Test emotional progression realism in conversations
        for conversation in conversations_data["conversations"][:3]:  # Check first few
            if "emotional_arc" in conversation:
                arc = conversation["emotional_arc"]
                if "progression" in arc and len(arc["progression"]) > 1:
                    # Check that emotional transitions are reasonable
                    progression = arc["progression"]
                    for i in range(len(progression) - 1):
                        current = progression[i]
                        next_emotion = progression[i + 1]
                        # Basic sanity check - emotions should be valid
                        valid_emotions = {"neutral", "happy", "sad", "angry", "fear", "surprise", "disgust", "stressed", "hopeful"}
                        assert current in valid_emotions, f"Invalid emotion in progression: {current}"
                        assert next_emotion in valid_emotions, f"Invalid emotion in progression: {next_emotion}"
        
        print("âœ… Data relationships and consistency tests complete")
    
    def test_crisis_scenario_handling(self, demo_generator, test_config):
        """
        Test that crisis scenarios are properly generated and handled
        Requirements: 4.4, 4.5
        """
        # Ensure crisis scenarios are enabled
        test_config.include_crisis_scenarios = True
        test_config.crisis_scenario_percentage = 0.5  # Higher percentage for testing
        
        result = demo_generator.generate_all_data(test_config)
        assert result.success, "Data generation failed"
        
        print("ðŸ§ª Testing crisis scenario handling...")
        
        storage = LocalStorageManager(test_config.output_directory)
        conversations_data = storage.load_data("conversations")
        
        # Find crisis conversations
        crisis_conversations = []
        for conv in conversations_data["conversations"]:
            if "emotional_arc" in conv and "crisis_level" in conv["emotional_arc"]:
                if conv["emotional_arc"]["crisis_level"] in ["medium", "high"]:
                    crisis_conversations.append(conv)
        
        # Should have at least one crisis conversation given the high percentage
        assert len(crisis_conversations) > 0, "No crisis scenarios found despite being enabled"
        
        # Validate crisis conversation structure
        crisis_conv = crisis_conversations[0]
        assert "messages" in crisis_conv, "Crisis conversation missing messages"
        assert len(crisis_conv["messages"]) > 0, "Crisis conversation has no messages"
        
        # Check for appropriate escalation patterns
        emotional_arc = crisis_conv["emotional_arc"]
        assert "progression" in emotional_arc, "Crisis conversation missing emotional progression"
        
        progression = emotional_arc["progression"]
        # Crisis conversations should show some emotional intensity
        intense_emotions = {"sad", "angry", "fear", "stressed"}
        has_intensity = any(emotion in intense_emotions for emotion in progression)
        assert has_intensity, f"Crisis conversation lacks emotional intensity: {progression}"
        
        print("âœ… Crisis scenario handling tests complete")
    
    def test_frontend_data_compatibility(self, demo_generator, test_service_config):
        """
        Test that generated data is compatible with frontend expectations
        Requirements: 4.1, 4.2, 4.3
        """
        # Generate data and launch services
        result = demo_generator.generate_all_data()
        assert result.success, "Data generation failed"
        
        launch_result = demo_generator.launch_complete_demo(auto_browser=False, config=test_service_config)
        
        try:
            assert launch_result["success"], "Service launch failed"
            api_url = launch_result["urls"]["api"]
            
            # Wait for services
            time.sleep(3)
            
            print("ðŸ§ª Testing frontend data compatibility...")
            
            # Test that API responses match expected frontend schemas
            
            # Test user profile schema
            response = requests.get(f"{api_url}/api/users", timeout=10)
            assert response.status_code == 200
            users_data = response.json()
            
            user = users_data["users"][0]
            # Check required fields for frontend
            frontend_required_fields = ["id", "age", "gender", "location", "primary_language"]
            for field in frontend_required_fields:
                assert field in user, f"User missing frontend required field: {field}"
            
            # Check baseline data structure
            assert "baseline_data" in user, "User missing baseline_data"
            baseline = user["baseline_data"]
            baseline_fields = ["voice_patterns", "emotional_patterns"]
            for field in baseline_fields:
                assert field in baseline, f"Baseline data missing field: {field}"
            
            # Test conversation schema
            user_id = user["id"]
            response = requests.get(f"{api_url}/api/conversations/{user_id}", timeout=10)
            assert response.status_code == 200
            conv_data = response.json()
            
            if conv_data["conversations"]:
                conversation = conv_data["conversations"][0]
                conv_fields = ["id", "messages", "emotional_arc"]
                for field in conv_fields:
                    assert field in conversation, f"Conversation missing frontend field: {field}"
                
                # Check message structure
                if conversation["messages"]:
                    message = conversation["messages"][0]
                    msg_fields = ["id", "text", "speaker", "timestamp"]
                    for field in msg_fields:
                        assert field in message, f"Message missing frontend field: {field}"
            
            # Test emotion analysis response schema
            test_message = {
                "text": "I feel overwhelmed with my studies",
                "user_id": user_id
            }
            
            response = requests.post(f"{api_url}/api/analyze/emotion", json=test_message, timeout=10)
            assert response.status_code == 200
            emotion_data = response.json()
            
            # Check emotion response structure
            emotion_fields = ["emotion", "confidence"]
            for field in emotion_fields:
                assert field in emotion_data, f"Emotion response missing field: {field}"
            
            # Validate emotion values
            assert emotion_data["emotion"] in ["neutral", "happy", "sad", "angry", "fear", "surprise", "disgust", "stressed"]
            assert 0 <= emotion_data["confidence"] <= 1
            
            print("âœ… Frontend data compatibility tests complete")
            
        finally:
            demo_generator.cleanup_all_data()
    
    def test_system_cleanup_and_state_management(self, demo_generator, test_config):
        """
        Test that cleanup properly removes all data and stops services
        Requirements: 4.5
        """
        # Generate data and launch services
        result = demo_generator.generate_all_data(test_config)
        assert result.success, "Data generation failed"
        
        launch_result = demo_generator.launch_complete_demo(auto_browser=False)
        assert launch_result["success"], "Service launch failed"
        
        # Verify services are running
        status = demo_generator.get_system_status()
        assert status["health"] in ["healthy", "partial"], f"System not healthy before cleanup: {status['health']}"
        
        print("ðŸ§ª Testing system cleanup...")
        
        # Perform cleanup
        cleanup_success = demo_generator.cleanup_all_data()
        assert cleanup_success, "Cleanup failed"
        
        # Verify cleanup was thorough
        storage = LocalStorageManager(test_config.output_directory)
        
        # Check that data files are removed
        assert storage.validate_clean_state(), "Storage not in clean state after cleanup"
        
        # Verify services are stopped
        final_status = demo_generator.get_system_status()
        services_stopped = all(not service["running"] for service in final_status["services"].values())
        assert services_stopped, "Some services still running after cleanup"
        
        # Verify no data remains
        assert final_status["data"]["total_files"] == 0, "Data files remain after cleanup"
        
        print("âœ… System cleanup and state management tests complete")


class TestEndToEndPerformance:
    """Performance-focused end-to-end tests"""
    
    def test_data_generation_performance_baseline(self):
        """
        Baseline performance test for data generation
        Requirements: 6.1, 6.2
        """
        with tempfile.TemporaryDirectory() as temp_dir:
            # Small dataset for baseline
            config = DemoConfig(
                num_users=5,
                conversations_per_user=3,
                cultural_scenarios=10,
                swahili_patterns=20,
                output_directory=temp_dir
            )
            
            config_manager = ConfigurationManager()
            config_manager.update_demo_config(config)
            generator = DemoDataGenerator(config_manager)
            
            print("ðŸ§ª Testing data generation performance...")
            
            start_time = time.time()
            result = generator.generate_all_data(config)
            generation_time = time.time() - start_time
            
            assert result.success, f"Data generation failed: {result.errors}"
            
            # Performance assertions (reasonable for small dataset)
            assert generation_time < 30, f"Data generation too slow: {generation_time:.2f}s"
            assert result.generation_time_seconds < 30, f"Reported generation time too slow: {result.generation_time_seconds:.2f}s"
            
            # Verify data quality wasn't sacrificed for speed
            assert result.users_generated == config.num_users
            assert result.conversations_generated == config.num_users * config.conversations_per_user
            
            print(f"âœ… Baseline performance test complete: {generation_time:.2f}s for {result.users_generated} users")
    
    def test_service_startup_performance(self):
        """
        Test service startup performance
        Requirements: 6.1, 6.2
        """
        with tempfile.TemporaryDirectory() as temp_dir:
            config = DemoConfig(
                num_users=2,
                conversations_per_user=2,
                output_directory=temp_dir
            )
            
            service_config = ServiceConfig(
                mock_api_port=8902,
                frontend_port=3902,
                auto_open_browser=False
            )
            
            config_manager = ConfigurationManager()
            config_manager.update_demo_config(config)
            config_manager.update_service_config(service_config)
            generator = DemoDataGenerator(config_manager)
            
            # Generate minimal data first
            result = generator.generate_all_data(config)
            assert result.success, "Data generation failed"
            
            print("ðŸ§ª Testing service startup performance...")
            
            try:
                start_time = time.time()
                launch_result = generator.launch_complete_demo(auto_browser=False, config=service_config)
                startup_time = time.time() - start_time
                
                assert launch_result["success"], f"Service launch failed: {launch_result['errors']}"
                
                # Performance assertion
                assert startup_time < 15, f"Service startup too slow: {startup_time:.2f}s"
                
                # Verify services are actually responsive
                api_url = launch_result["urls"]["api"]
                response = requests.get(f"{api_url}/health", timeout=5)
                assert response.status_code == 200, "API not responsive after startup"
                
                print(f"âœ… Service startup performance test complete: {startup_time:.2f}s")
                
            finally:
                generator.cleanup_all_data()


if __name__ == "__main__":
    # Run tests directly
    pytest.main([__file__, "-v", "-s"])